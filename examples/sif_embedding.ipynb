{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import data_io, params, SIF_embedding\n",
    "\n",
    "# input\n",
    "wordfile = '../data/glove.840B.300d.txt' # word vector file, can be downloaded from GloVe website\n",
    "weightfile = '../auxiliary_data/enwiki_vocab_min200.txt' # each line is a word and its frequency\n",
    "weightpara = 1e-3 # the parameter in the SIF weighting scheme, usually in the range [3e-5, 3e-3]\n",
    "rmpc = 1 # number of principal components to remove in SIF weighting scheme\n",
    "sentences = ['this is an example sentence', 'this is another sentence that is slightly longer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word vectors\n",
    "(words, We) = data_io.getWordmap(wordfile)  # fails with python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word weights\n",
    "word2weight = data_io.getWordWeight(weightfile, weightpara) # word2weight['str'] is the weight for the word 'str'\n",
    "weight4ind = data_io.getWeight(words, word2weight) # weight4ind[i] is the weight for the i-th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sentences\n",
    "x, m = data_io.sentences2idx(sentences, words) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "w = data_io.seq2weight(x, m, weight4ind) # get word weights\n",
    "# https://github.com/PrincetonML/SIF/issues/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "paramsz = params.params()\n",
    "paramsz.rmpc = rmpc\n",
    "# get SIF embedding\n",
    "embeddings = SIF_embedding.SIF_embedding(We, x, w, paramsz) # embedding[i,:] is the embedding for sentence i\n",
    "# print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [[\"Obama was born in Kenya.\", \"Obama was born in Kenya.\"],\n",
    "         [\"Obama was born in Kenya.\", \"Obama is born in Kenya.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Obama was not born in Kenya.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Obama was delivered in Kenya.\"],\n",
    "        [\"Obama was born in Kenya.\", \"The place of birth of Obama in Kenya.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Obama was born in New York.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Obama has visited Kenya's president's birthplace.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Obama is a Muslim.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Obama is a Muslim and was born in Kenya.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Obama is trying to take our guns away.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Obama was born in Kenya and is going to take our guns away.\"],\n",
    "        [\"Obama was born in Kenya.\", \"I like ice cream.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Lee Kwan Yew was a dictator.\"],\n",
    "        [\"Obama was born in Kenya.\", \"Trump is a dictator.\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for embedding in embeddings:\n",
    "#     print(np.dot(embedding[1], embedding[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Obama was born in Kenya.', 'Obama was born in Kenya.']\n",
      "5.714164982031733e-30\n",
      "['Obama was born in Kenya.', 'Obama is born in Kenya.']\n",
      "-0.0027471106174365\n",
      "['Obama was born in Kenya.', 'Obama was not born in Kenya.']\n",
      "-0.01357030393632308\n",
      "['Obama was born in Kenya.', 'Obama was delivered in Kenya.']\n",
      "-0.4229691036033214\n",
      "['Obama was born in Kenya.', 'The place of birth of Obama in Kenya.']\n",
      "-0.16140164298688744\n",
      "['Obama was born in Kenya.', 'Obama was born in New York.']\n",
      "-0.03483757200155936\n",
      "['Obama was born in Kenya.', \"Obama has visited Kenya's president's birthplace.\"]\n",
      "-0.6234574916478155\n",
      "['Obama was born in Kenya.', 'Obama is a Muslim.']\n",
      "-0.2906303238160426\n",
      "['Obama was born in Kenya.', 'Obama is a Muslim and was born in Kenya.']\n",
      "-0.1941008408880345\n",
      "['Obama was born in Kenya.', 'Obama is trying to take our guns away.']\n",
      "-2.199842662694401\n",
      "['Obama was born in Kenya.', 'Obama was born in Kenya and is going to take our guns away.']\n",
      "-0.9269503903983384\n",
      "['Obama was born in Kenya.', 'I like ice cream.']\n",
      "-3.8456665684721973\n",
      "['Obama was born in Kenya.', 'Lee Kwan Yew was a dictator.']\n",
      "-1.7168057028953758\n",
      "['Obama was born in Kenya.', 'Trump is a dictator.']\n",
      "-0.9596032000951744\n"
     ]
    }
   ],
   "source": [
    "for pair in pairs:\n",
    "    sentences = pair\n",
    "    # load sentences\n",
    "    x, m = data_io.sentences2idx(sentences, words) # x is the array of word indices, m is the binary mask indicating whether there is a word in that location\n",
    "    w = data_io.seq2weight(x, m, weight4ind) # get word weights\n",
    "    # https://github.com/PrincetonML/SIF/issues/25\n",
    "    \n",
    "    # set parameters\n",
    "    paramsz = params.params()\n",
    "    paramsz.rmpc = rmpc\n",
    "    # get SIF embedding\n",
    "    embeddings = SIF_embedding.SIF_embedding(We, x, w, paramsz) # embedding[i,:] is the embedding for sentence i\n",
    "#     print(embeddings)\n",
    "    print(pair)\n",
    "    print(np.dot(embeddings[0], embeddings[1]))\n",
    "#     print(np.dot(embeddings[0], embeddings[1])/(np.linalg.norm(embeddings[0])*np.linalg.norm(embeddings[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions like GPA, minus from 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
